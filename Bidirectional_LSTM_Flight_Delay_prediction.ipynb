{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1f3ytohdQvrqn10gnF9Bq_96eHXcEIWbW",
      "authorship_tag": "ABX9TyN+8pfJjjGuYMt82kX7HWxq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/It21258794/DL_Assignment_SE4050/blob/main/Bidirectional_LSTM_Flight_Delay_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bidirectional LSTM Model **"
      ],
      "metadata": {
        "id": "jlB2VFW0Ydyd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrcCwnCUXnl1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the data set\n",
        "path = \"/content/drive/MyDrive/flights_sample_3m.csv.zip\""
      ],
      "metadata": {
        "id": "AnqtEwcLeJ_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the dataset\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# checking the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4ODXZ-eEeKpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['ARR_DELAY'] > 0]"
      ],
      "metadata": {
        "id": "zPEm2PvAeM12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the shape of the dataset and the number of rows and columns\n",
        "df.shape"
      ],
      "metadata": {
        "id": "oCvSfkhdePJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the data types of the columns\n",
        "df.info()"
      ],
      "metadata": {
        "id": "k0FM9PWgeVJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the categorical data\n",
        "le = LabelEncoder()\n",
        "\n",
        "def clean_labels_encoder(list_of_labels, df):\n",
        "  for label in list_of_labels:\n",
        "        df[label] = le.fit_transform(df[label])\n",
        "  return df"
      ],
      "metadata": {
        "id": "zb55dBONeXsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_time_columns(df):\n",
        "    # Convert 'hhmm' format into 'hours' and 'minutes' for both CRS_DEP_TIME and CRS_ARR_TIME\n",
        "    df['CRS_DEP_HOUR'] = df['CRS_DEP_TIME'] // 100  # Extract hour part\n",
        "    df['CRS_DEP_MINUTE'] = df['CRS_DEP_TIME'] % 100  # Extract minute part\n",
        "    df['CRS_ARR_HOUR'] = df['CRS_ARR_TIME'] // 100  # Extract hour part\n",
        "    df['CRS_ARR_MINUTE'] = df['CRS_ARR_TIME'] % 100  # Extract minute part\n",
        "\n",
        "    # create a time period (morning, afternoon, etc.)\n",
        "    df['DEP_TIME_PERIOD'] = pd.cut(df['CRS_DEP_HOUR'], bins=[0, 6, 12, 18, 24],\n",
        "                                   labels=['Night', 'Morning', 'Afternoon', 'Evening'], right=False)\n",
        "    return df"
      ],
      "metadata": {
        "id": "FBdO66zgeatw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_flight_data(df):\n",
        "    df['FL_DATE'] = pd.to_datetime(df['FL_DATE'], errors='coerce')  # Auto-infer format\n",
        "\n",
        "    # Extract relevant date features\n",
        "    df['DayOfWeek'] = df['FL_DATE'].dt.weekday  # 0=Monday, 6=Sunday\n",
        "    df['IsWeekend'] = df['DayOfWeek'] >= 5  # True if weekend (Saturday/Sunday)\n",
        "\n",
        "    # Process the time columns (CRS_DEP_TIME, CRS_ARR_TIME)\n",
        "    df = process_time_columns(df)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "IjM4_o9pedSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = process_flight_data(df)"
      ],
      "metadata": {
        "id": "I2h2EHJ4efaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = [\n",
        "    'CANCELLED',\n",
        "    'CANCELLATION_CODE',\n",
        "    'TAXI_OUT',\n",
        "    'WHEELS_OFF',\n",
        "    'WHEELS_ON',\n",
        "    'TAXI_IN',\n",
        "    'DELAY_DUE_CARRIER',\n",
        "    'DELAY_DUE_WEATHER',\n",
        "    'DELAY_DUE_NAS',\n",
        "    'DELAY_DUE_SECURITY',\n",
        "    'DELAY_DUE_LATE_AIRCRAFT',\n",
        "    'DOT_CODE',\n",
        "    'AIRLINE_CODE',\n",
        "    'ORIGIN_CITY' ,\n",
        "    'DEST_CITY',\n",
        "    'AIRLINE_DOT',\n",
        "    'FL_NUMBER',\n",
        "    'DIVERTED',\n",
        "    'FL_DATE'\n",
        "]"
      ],
      "metadata": {
        "id": "YiWhIPkPeiN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=columns_to_drop)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "yghj3LNnekhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "def clean_labels_encoder(list_of_labels, df):\n",
        "    for label in list_of_labels:\n",
        "        df[label] = le.fit_transform(df[label])\n",
        "    return df"
      ],
      "metadata": {
        "id": "_iYQvPURemi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean the labels\n",
        "list_of_labels = ['AIRLINE','ORIGIN', 'DEST','DEP_TIME_PERIOD']\n",
        "df = clean_labels_encoder(list_of_labels, df)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FeFQNDBseqdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# describe the dataset\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "cThWs5dhevMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_delay = df['ARR_DELAY'].min()\n",
        "max_delay = df['ARR_DELAY'].max()\n",
        "mean_delay = df['ARR_DELAY'].mean()\n",
        "std_delay = df['ARR_DELAY'].std()\n",
        "\n",
        "print(f\"Min delay: {min_delay}\")\n",
        "print(f\"Max delay: {max_delay}\")\n",
        "print(f\"Mean delay: {mean_delay}\")\n",
        "print(f\"Standard deviation: {std_delay}\")"
      ],
      "metadata": {
        "id": "BBwBeD0Vev2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill the missing values with mean\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# show correlation\n",
        "df.corr()"
      ],
      "metadata": {
        "id": "dVsZQtGoezGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the correlation in a plt figure\n",
        "\n",
        "def show_correlation(df):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    sns.set(style='whitegrid', context='notebook')\n",
        "    sns.heatmap(df.corr(), annot=True, square=False, cmap='coolwarm')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "72uG5rXpe1GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the correlation\n",
        "show_correlation(df)"
      ],
      "metadata": {
        "id": "aCyXuz4se3Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into features and target\n",
        "# target is ARR_DELAY\n",
        "\n",
        "X = df.drop(columns=['ARR_DELAY'])\n",
        "y = df['ARR_DELAY']"
      ],
      "metadata": {
        "id": "wLPKvxUhe5Xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training+validation and test sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
        "\n",
        "# Split the training+validation set into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.3, shuffle=False)"
      ],
      "metadata": {
        "id": "R7aiiSdXe7gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "df['ARR_DELAY'] = scaler.fit_transform(df[['ARR_DELAY']])"
      ],
      "metadata": {
        "id": "2idd60dRe9ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"After Scaling - Min delay: {df['ARR_DELAY'].min()}\")\n",
        "print(f\"After Scaling - Max delay: {df['ARR_DELAY'].max()}\")\n",
        "print(f\"After Scaling - Mean delay: {df['ARR_DELAY'].mean()}\")\n",
        "print(f\"After Scaling - Standard deviation: {df['ARR_DELAY'].std()}\")"
      ],
      "metadata": {
        "id": "o0Vv-bZVfAoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X_train = scaler_X.fit_transform(X_train)\n",
        "X_val = scaler_X.transform(X_val)\n",
        "X_test = scaler_X.transform(X_test)\n",
        "\n",
        "# Reshape y_train, y_val, and y_test into 2D arrays, scale them\n",
        "y_train = y_train.values.reshape(-1, 1)  # Convert to numpy array and reshape\n",
        "y_val = y_val.values.reshape(-1, 1)\n",
        "y_test = y_test.values.reshape(-1, 1)\n",
        "\n",
        "y_train = scaler_y.fit_transform(y_train)\n",
        "y_val = scaler_y.transform(y_val)\n",
        "y_test = scaler_y.transform(y_test)"
      ],
      "metadata": {
        "id": "JFJdbbiIfC7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the data for input to the LSTM model\n",
        "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
        "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "metadata": {
        "id": "C2juqHs_fFlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Bidirectional LSTM model architecture\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(1, X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(16))\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "GqujZT7kfHY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])"
      ],
      "metadata": {
        "id": "-JC7bOUPfPD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test),\n",
        "                    verbose=2, shuffle=False, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "Ozag6Q2ZfR99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C-PIt1zIfxJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss (MSE):', score[0])\n",
        "print('Test MAE:', score[1])"
      ],
      "metadata": {
        "id": "y0vgpGUMfUTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and plot the results\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = scaler_y.inverse_transform(y_pred)\n",
        "y_test = scaler_y.inverse_transform(y_test)"
      ],
      "metadata": {
        "id": "03BO7trHfYsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test, label='Actual Values', color='blue', alpha=0.7)\n",
        "plt.plot(y_pred, label='Predicted Values', color='red', alpha=0.7)\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Actual vs Predicted Values (Bidirectional LSTM)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TtUBiAIyfZFk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}